{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a62acba",
   "metadata": {},
   "source": [
    "Objective: get_history should fetch all the data at once then save it to separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9457c197",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audiolizer temp data: /home/audiolizer/audiolizer/history\n",
      "audiolizer max daily age 0 days 00:05:00\n"
     ]
    }
   ],
   "source": [
    "from Historic_Crypto import HistoricalData\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "granularity = int(os.environ.get('AUDIOLIZER_GRANULARITY', 300)) # seconds\n",
    "\n",
    "audiolizer_temp_dir = os.environ.get('AUDIOLIZER_TEMP', './history/')\n",
    "print('audiolizer temp data:', audiolizer_temp_dir)\n",
    "\n",
    "max_age = pd.Timedelta(os.environ.get('AUDIOLIZER_MAX_AGE', '5m'))\n",
    "print('audiolizer max daily age {}'.format(max_age))\n",
    "\n",
    "def refactor(df, frequency='1W'):\n",
    "    \"\"\"Refactor/rebin the data to a lower cadence\n",
    "\n",
    "    The data is regrouped using pd.Grouper\n",
    "    \"\"\"\n",
    "    low = df.low.groupby(pd.Grouper(freq=frequency)).min()\n",
    "    high = df.high.groupby(pd.Grouper(freq=frequency)).max()\n",
    "    close = df.close.groupby(pd.Grouper(freq=frequency)).last()\n",
    "    open_ = df.open.groupby(pd.Grouper(freq=frequency)).first()\n",
    "    volume = df.volume.groupby(pd.Grouper(freq=frequency)).sum()\n",
    "    return pd.DataFrame(dict(low=low, high=high, open=open_, close=close, volume=volume))\n",
    "\n",
    "\n",
    "def load_date(ticker, granularity, int_):\n",
    "    print('loading single date {}'.format(int_))\n",
    "    start_ = int_.left.strftime('%Y-%m-%d-%H-%M')\n",
    "    end_ = int_.right.strftime('%Y-%m-%d-%H-%M')\n",
    "    try:\n",
    "        return HistoricalData(ticker,\n",
    "                              granularity,\n",
    "                              start_,\n",
    "                              end_,\n",
    "                              ).retrieve_data()\n",
    "    except:\n",
    "        print('could not load using {} {}'.format(start_, end_))\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_gaps(df, granularity):\n",
    "    new_ = refactor(df, '{}s'.format(granularity))\n",
    "    return new_[new_.close.isna()]\n",
    "\n",
    "\n",
    "def fetch_data(ticker, granularity, start_, end_):\n",
    "    \"\"\"Need dates in this format %Y-%m-%d-%H-%M\"\"\"\n",
    "    try:\n",
    "        return HistoricalData(ticker,\n",
    "                              granularity,\n",
    "                              start_,\n",
    "                              end_,\n",
    "                              ).retrieve_data()\n",
    "    except:\n",
    "        print('could not load using {} {}'.format(start_, end_))\n",
    "        raise\n",
    "\n",
    "\n",
    "def write_data(df, ticker):\n",
    "    for t, day in df.groupby(pd.Grouper(freq='1D')):\n",
    "        tstr = t.strftime('%Y-%m-%d-%H-%M')\n",
    "        fname = audiolizer_temp_dir + '/{}-{}.csv.gz'.format(\n",
    "                ticker, t.strftime('%Y-%m-%d'))\n",
    "        if len(day) > 1:\n",
    "            day.to_csv(fname, compression='gzip')\n",
    "            print('wrote {}'.format(fname))\n",
    "        \n",
    "def fetch_missing(files_status, ticker, granularity):\n",
    "    \"\"\"Iterate over batches of missing dates\"\"\"\n",
    "    for batch, g in files_status[files_status.found==0].groupby('batch', sort=False):\n",
    "        t1, t2 = g.iloc[[0, -1]].index\n",
    "        # extend by 1 day whether or not t1 == t2\n",
    "        t2 += pd.Timedelta('1D')\n",
    "        endpoints = [t.strftime('%Y-%m-%d-%H-%M') for t in [t1, t2]]\n",
    "        print('fetching {}, {}'.format(len(g), endpoints))\n",
    "        df = fetch_data(ticker, granularity, *endpoints)\n",
    "        write_data(df, ticker)\n",
    "\n",
    "        \n",
    "def get_files_status(ticker, start_date, end_date):\n",
    "    fnames = []\n",
    "    foundlings = []\n",
    "    dates = []\n",
    "    batch = []\n",
    "    batch_number = 0\n",
    "    last_found = -1\n",
    "    for int_ in pd.interval_range(start_date, end_date):\n",
    "        dates.append(int_.left)\n",
    "        fname = audiolizer_temp_dir + '/{}-{}.csv.gz'.format(\n",
    "            ticker, int_.left.strftime('%Y-%m-%d'))\n",
    "        found = int(os.path.exists(fname))\n",
    "        foundlings.append(found)\n",
    "        if found != last_found:\n",
    "            batch_number += 1\n",
    "        last_found = found\n",
    "        batch.append(batch_number)\n",
    "        fnames.append(fname)\n",
    "    files_status = pd.DataFrame(dict(files=fnames, found=foundlings, batch=batch), index=dates)\n",
    "    return files_status\n",
    "\n",
    "\n",
    "def get_today(ticker, granularity):\n",
    "    today = pd.Timestamp.now().tz_localize(None)\n",
    "    tomorrow = today + pd.Timedelta('1D')\n",
    "    start_ = '{}-00-00'.format(today.strftime('%Y-%m-%d'))\n",
    "    end_ = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    try:\n",
    "        return HistoricalData(ticker,\n",
    "                              granularity,\n",
    "                              start_,\n",
    "                              end_,\n",
    "                              ).retrieve_data()\n",
    "    except:\n",
    "        print('could not load using {} {}'.format(start_, end_))\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_age(fname):\n",
    "    \"\"\"Get the age of a given a file\"\"\"\n",
    "    st=os.stat(fname)    \n",
    "    mtime=st.st_mtime\n",
    "    return pd.Timestamp.now() - datetime.fromtimestamp(mtime)\n",
    "    \n",
    "        \n",
    "def get_history(ticker, start_date, end_date = None, granularity=granularity):\n",
    "    \"\"\"Fetch/load historical data from Coinbase API at specified granularity\n",
    "    \n",
    "    Data loaded from start_date through end of end_date\n",
    "    params:\n",
    "        start_date: (str) (see pandas.to_datetime for acceptable formats)\n",
    "        end_date: (str)\n",
    "        granularity: (int) seconds (default: 300)\n",
    "\n",
    "    price data is saved by ticker and date and stored in audiolizer_temp_dir\n",
    "    \"\"\"\n",
    "    start_date = pd.to_datetime(start_date).tz_localize(None)\n",
    "    \n",
    "    today = pd.Timestamp.now().tz_localize(None)\n",
    "    if end_date is None:\n",
    "        # don't include today\n",
    "        end_date = today # + pd.Timedelta('1D')\n",
    "    else:\n",
    "        end_date = min(today, pd.to_datetime(end_date).tz_localize(None))\n",
    "        \n",
    "    files_status = get_files_status(ticker, start_date, end_date)\n",
    "    fetch_missing(files_status, ticker, granularity)\n",
    "        \n",
    "\n",
    "    df = pd.concat(map(lambda file: pd.read_csv(file, index_col='time', parse_dates=True, compression='gzip'),\n",
    "                         files_status.files)).drop_duplicates()\n",
    "\n",
    "    if end_date == today:\n",
    "        print('end date is today!')\n",
    "        # check age of today's data. If it's old, fetch the new one\n",
    "        today_fname = audiolizer_temp_dir + '/{}-today.csv.gz'.format(ticker)\n",
    "        if os.path.exists(today_fname):\n",
    "            if get_age(today_fname) > max_age:\n",
    "                print('{} is too old, fetching new data'.format(today_fname))\n",
    "                today_data = get_today(ticker, granularity)\n",
    "                today_data.to_csv(today_fname, compression='gzip')\n",
    "            else:\n",
    "                print('{} is not that old, loading from disk'.format(today_fname))\n",
    "                today_data = pd.read_csv(today_fname, index_col='time', parse_dates=True, compression='gzip')\n",
    "        else:\n",
    "            print('{} not present. loading'.format(today_fname))\n",
    "            today_data = get_today(ticker, granularity)\n",
    "            today_data.to_csv(today_fname, compression='gzip')\n",
    "        df = pd.concat([df, today_data]).drop_duplicates()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6107edca",
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end date is today!\n",
      "/home/audiolizer/audiolizer/history/BTC-USD-today.csv.gz is too old, fetching new data\n",
      "Checking input parameters are in the correct format...\n",
      "Formatting Dates...\n",
      "Checking if ticker supplied is available on the CoinBase Pro API...\n",
      "Connected to the CoinBase Pro API...\n",
      "Ticker 'BTC-USD' found at the CoinBase Pro API, continuing to extraction...\n",
      "Data Extracted from API...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-07 00:00:00</th>\n",
       "      <td>34139.91</td>\n",
       "      <td>34231.37</td>\n",
       "      <td>34225.72</td>\n",
       "      <td>34211.72</td>\n",
       "      <td>20.737341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07 00:05:00</th>\n",
       "      <td>34205.71</td>\n",
       "      <td>34400.00</td>\n",
       "      <td>34205.71</td>\n",
       "      <td>34398.01</td>\n",
       "      <td>45.697437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07 00:10:00</th>\n",
       "      <td>34331.08</td>\n",
       "      <td>34416.34</td>\n",
       "      <td>34398.01</td>\n",
       "      <td>34334.97</td>\n",
       "      <td>28.338220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07 00:15:00</th>\n",
       "      <td>34260.00</td>\n",
       "      <td>34385.03</td>\n",
       "      <td>34338.35</td>\n",
       "      <td>34271.96</td>\n",
       "      <td>19.066806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07 00:20:00</th>\n",
       "      <td>34200.20</td>\n",
       "      <td>34277.97</td>\n",
       "      <td>34271.96</td>\n",
       "      <td>34217.88</td>\n",
       "      <td>22.407736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-11 03:35:00</th>\n",
       "      <td>33489.48</td>\n",
       "      <td>33512.69</td>\n",
       "      <td>33512.69</td>\n",
       "      <td>33493.43</td>\n",
       "      <td>8.225350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-11 03:40:00</th>\n",
       "      <td>33492.60</td>\n",
       "      <td>33498.32</td>\n",
       "      <td>33493.44</td>\n",
       "      <td>33493.44</td>\n",
       "      <td>0.178586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 00:00:00</th>\n",
       "      <td>34181.08</td>\n",
       "      <td>34335.80</td>\n",
       "      <td>34259.22</td>\n",
       "      <td>34331.91</td>\n",
       "      <td>62.818703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 00:05:00</th>\n",
       "      <td>34200.52</td>\n",
       "      <td>34342.52</td>\n",
       "      <td>34331.91</td>\n",
       "      <td>34237.58</td>\n",
       "      <td>32.625492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 00:10:00</th>\n",
       "      <td>34111.11</td>\n",
       "      <td>34232.64</td>\n",
       "      <td>34230.96</td>\n",
       "      <td>34115.51</td>\n",
       "      <td>24.309228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          low      high      open     close     volume\n",
       "time                                                                  \n",
       "2021-07-07 00:00:00  34139.91  34231.37  34225.72  34211.72  20.737341\n",
       "2021-07-07 00:05:00  34205.71  34400.00  34205.71  34398.01  45.697437\n",
       "2021-07-07 00:10:00  34331.08  34416.34  34398.01  34334.97  28.338220\n",
       "2021-07-07 00:15:00  34260.00  34385.03  34338.35  34271.96  19.066806\n",
       "2021-07-07 00:20:00  34200.20  34277.97  34271.96  34217.88  22.407736\n",
       "...                       ...       ...       ...       ...        ...\n",
       "2021-07-11 03:35:00  33489.48  33512.69  33512.69  33493.43   8.225350\n",
       "2021-07-11 03:40:00  33492.60  33498.32  33493.44  33493.44   0.178586\n",
       "2021-07-12 00:00:00  34181.08  34335.80  34259.22  34331.91  62.818703\n",
       "2021-07-12 00:05:00  34200.52  34342.52  34331.91  34237.58  32.625492\n",
       "2021-07-12 00:10:00  34111.11  34232.64  34230.96  34115.51  24.309228\n",
       "\n",
       "[1200 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = get_history('BTC-USD',\n",
    "                   pd.Timestamp.now().tz_localize(None)-pd.Timedelta('5D'),\n",
    "#                   pd.Timestamp.now().tz_localize(None)-pd.Timedelta('3D'),\n",
    "                  )\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186ed12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading history.ipynb in format ipynb\n",
      "[jupytext] Updating history.py\n"
     ]
    }
   ],
   "source": [
    "!jupytext --sync history.ipynb"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
